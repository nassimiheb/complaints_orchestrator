Customer Complaints Resolution Orchestrator
Presentation Notes - Decisions, Implementations, and Oral Script (Phase 0 to Phase 4)

How to use this file:
- "What we implemented" = concrete delivery.
- "Decision and why" = architecture choice + rationale.
- "How to explain orally" = ready-to-say presentation phrasing.

------------------------------------------------------------
PHASE 0 - PROJECT BOOTSTRAP
------------------------------------------------------------
Goal:
Create a runnable, clean base project before business logic.

What we implemented:
- Repository scaffold under `complaints_orchestrator/`.
- Python package structure under `src/complaints_orchestrator/`.
- `requirements.txt` with LangGraph, LangChain, Chroma, Pydantic, dotenv, sqlite tooling.
- `.env.example` with Mistral provider settings and thresholds.
- Base config module (`config.py`) and logging module (`logging_config.py`).
- CLI entrypoint (`src/main.py`) with `--help`, `--scenario`, and `--env-file`.

Decisions and why:
1) Decision: Start with a strict package layout (`src/` pattern).
Why:
- Prevents import confusion.
- Scales cleanly as modules grow (agents/tools/rag/memory/eval/utils).

2) Decision: Put provider and thresholds in environment config from day one.
Why:
- Avoid hardcoding sensitive values and runtime policies.
- Makes the system portable across machines and demo environments.

3) Decision: Keep Phase 0 CLI minimal (no business flow yet).
Why:
- Validate bootstrapping success quickly (`python src/main.py --help`).
- Reduce early complexity and isolate setup issues.

4) Decision: Align defaults to Mistral (`MISTRAL_API_KEY`, Mistral model names).
Why:
- Matches product requirements and prevents provider mismatch later.

How to explain orally:
"In Phase 0 we intentionally built only the foundation: package structure, config, logging, and a runnable CLI. We kept runtime logic out on purpose so environment and import issues are solved first. This gave us a stable base before implementing agents and policies."

------------------------------------------------------------
PHASE 1 - DOMAIN DATA AND SCHEMAS
------------------------------------------------------------
Goal:
Define domain contracts and initial synthetic data to make behavior testable.

What we implemented:
- Mock datasets:
  - `data/mock_customers.json`
  - `data/mock_orders.json`
  - `data/mock_cases.json`
- Domain enums/constants in `constants.py`:
  - decisions, routes, urgency, status, sentiment, risk flags, language.
- Tool schemas in `tools/schemas.py` (Pydantic).
- Graph state contract in `state.py` with required security fields:
  - `redacted_email_body`
  - `security_events`
  - `output_guard_passed`
- State validation test coverage in `tests/test_state_contract.py`.

Decisions and why:
1) Decision: Use Pydantic schemas for every tool input/output.
Why:
- Enforces strict contracts.
- Catches malformed payloads early.
- Supports auditability and safer multi-agent orchestration.

2) Decision: Use `extra="forbid"` in base schema models.
Why:
- Blocks undeclared keys.
- Reduces accidental leakage/noisy payload propagation.

3) Decision: Model graph state as explicit typed sub-objects (input/triage/context/resolution/finalize).
Why:
- Makes node contracts explicit and testable.
- Avoids ad hoc dict sprawl as graph complexity grows.

4) Decision: Include security fields directly in state from the start.
Why:
- Security becomes first-class data, not a later patch.
- Supports compliance traceability across nodes.

5) Decision: Keep mock data minimal and synthetic.
Why:
- Meets data minimization requirement.
- Avoids sensitive real-world data exposure.

How to explain orally:
"Phase 1 is where we locked the system contracts. We defined strict schemas for tools and graph state so every step is typed and validated. We also embedded security fields in the state model immediately, so compliance is part of the design rather than an afterthought."

------------------------------------------------------------
PHASE 2 - TOOLING LAYER AND PERMISSIONS
------------------------------------------------------------
Goal:
Build local tool APIs with strict role-based access and schema validation.

What we implemented:
- Tool modules:
  - `tools/crm.py`
  - `tools/oms.py`
  - `tools/cases.py`
  - `tools/actions.py`
  - `tools/tickets.py`
- Shared local JSON loader in `tools/data_store.py`.
- Retry utility in `utils/retry.py` (exponential backoff).
- Role-based registry in `tools/registry.py` with:
  - explicit allowlist
  - input validation
  - output validation
  - permission checks by node role
  - centralized execution path (`call_tool`)
- Phase tests in `tests/test_tool_registry.py`.
- Contract rename refinement: `recent_escalations` -> `recent_escalations_count`.

Decisions and why:
1) Decision: Centralize all tool invocation in registry.
Why:
- Single enforcement point for permissions + validation.
- Easier security review and future maintenance.

2) Decision: Separate read tools and action tools by role.
Why:
- Enforces least privilege.
- Satisfies requirement: action tools only available to `resolution_node`.

3) Decision: Validate output schemas, not just inputs.
Why:
- Detects tool implementation bugs.
- Prevents malformed data from contaminating agent reasoning.

4) Decision: Make action IDs deterministic (`uuid5` from payload).
Why:
- Improves test reproducibility.
- Keeps local mocks deterministic for demos.

5) Decision: Add retry wrapper even for local mocks.
Why:
- Establishes a robustness pattern now.
- Same call path can handle transient failures later (DB/network-like dependencies).

How to explain orally:
"In Phase 2 we treated tool calls as a controlled boundary. The registry became the gatekeeper: it validates schemas, enforces role permissions, logs calls, and applies retry logic. This gives deterministic behavior for demos and strong control for security and governance."

------------------------------------------------------------
PHASE 3 - PERSISTENT MEMORY
------------------------------------------------------------
Goal:
Introduce durable memory with privacy rules and queryable aggregates.

What we implemented:
- SQLite schema in `memory/schema.sql`:
  - `customers_memory`
  - `cases_memory`
  - indexes on customer and time dimensions.
- Storage adapter in `memory/store.py`:
  - upsert customer memory
  - upsert case memory
  - finalize helper (`record_finalize_update`)
  - query preferred language
  - query 90-day compensation total
- Seed script in `memory/seed_memory.py` to initialize DB from mock datasets.
- Tests in `tests/test_memory_store.py`.
- Memory package export in `memory/__init__.py`.

Decisions and why:
1) Decision: Use SQLite for persistent memory.
Why:
- Lightweight, local, deterministic, easy to demo.
- Meets "SQLite preferred" requirement.

2) Decision: Split memory into customer-level and case-level tables.
Why:
- Mirrors business needs:
  - customer preferences/history constraints,
  - case resolution audit trail.

3) Decision: Enforce no raw email persistence in adapter layer.
Why:
- Non-negotiable compliance rule.
- Blocking at write boundary is safer than relying on caller discipline.

4) Decision: Compute 90-day totals from case records, then sync customer aggregate.
Why:
- Keeps aggregate grounded in source records.
- Supports abuse/risk logic in later resolution scoring.

5) Decision: Explicit connection close pattern for sqlite.
Why:
- Avoids Windows file lock issues during tests and temp dir cleanup.

How to explain orally:
"Phase 3 made memory durable and policy-aware. We store only structured summaries, never raw email. We also track customer language and rolling 90-day compensation totals, which are key constraints for future decisioning and anti-abuse controls."

------------------------------------------------------------
PHASE 4 - RAG KNOWLEDGE BASE (CHROMA)
------------------------------------------------------------
Goal:
Build secure internal retrieval over policy documents.

What we implemented:
- Bilingual internal docs under `rag/documents/`:
  - refund policy (EN/FR)
  - compensation policy (EN/FR)
  - tone guidance (EN/FR)
- Security utilities in `utils/rag_security.py`:
  - source allowlist checks
  - suspicious pattern detection (prompt injection)
  - directive-like line stripping
  - chunking with overlap and bounds
  - metadata inference (`doc_id`, `language`, `policy_type`)
- Local deterministic embedding adapter in `rag/local_embeddings.py`.
- Secure index builder in `rag/build_index.py`:
  - chunks, sanitizes, skips suspicious content
  - writes metadata-rich records to Chroma
  - CLI entrypoint for build.
- Secure retriever in `rag/retriever.py`:
  - language filter
  - optional policy type filter
  - over-fetch for safe post-filtering
  - re-sanitization and suspicious-source rejection
  - structured retrieval output.
- Package exports in `rag/__init__.py`.
- Tests in `tests/test_rag_pipeline.py`.

Decisions and why:
1) Decision: Restrict RAG to internal docs directory and approved extensions.
Why:
- Prevents accidental ingestion of external/untrusted sources.
- Enforces "internal-only" policy requirement.

2) Decision: Apply injection/security checks in BOTH indexing and retrieval.
Why:
- Defense in depth.
- A malicious line can appear at ingest or survive in storage; both stages must filter.

3) Decision: Cap chunk/excerpt sizes and strip directive-like lines.
Why:
- Reduces attack surface and noisy instructions.
- Improves relevance and downstream prompt hygiene.

4) Decision: Use deterministic local embeddings for this phase.
Why:
- Offline, reproducible testing without API dependency.
- Keeps focus on pipeline/security correctness before provider-quality tuning.

5) Decision: Over-fetch retrieval candidates (`top_k * 3`) then post-filter.
Why:
- After security/source/type filters, many candidates can be dropped.
- Over-fetch keeps a high chance of returning requested `top_k` valid snippets.

6) Decision: Return structured retrieval payload (doc_id/language/policy_type/source/snippet/score).
Why:
- Clean integration contract for context agent.
- Avoids exposing raw Chroma internals directly.

How to explain orally:
"Phase 4 delivered secure internal RAG. We limited sources to approved internal docs, sanitized aggressively, blocked suspicious chunks, and attached metadata for language-aware retrieval. This gives policy grounding while reducing prompt-injection and leakage risks."

------------------------------------------------------------
CROSS-PHASE ARCHITECTURAL PRINCIPLES WE FOLLOWED
------------------------------------------------------------
1) Security by design:
- Security fields in state, schema validation at boundaries, tool permission gates, no raw email persistence, and RAG hardening.

2) Determinism for demos/tests:
- Deterministic IDs, local mocks, local embeddings, reproducible unit tests.

3) Clear contracts:
- Pydantic schemas + explicit state models + structured return payloads.

4) Incremental layering:
- Bootstrap -> contracts -> tools -> memory -> RAG.
- Each phase closes with tests and runnable validation.

How to explain orally:
"Our strategy was layered and test-first: each phase introduced one major capability with strict contracts and security controls. We optimized for reliability and traceability so the later multi-agent orchestration has stable, auditable building blocks."

------------------------------------------------------------
SHORT PRESENTATION SCRIPT (2-3 MIN)
------------------------------------------------------------
"We built the orchestrator in phases to reduce risk and keep quality high.
Phase 0 established a stable runnable project with environment-driven configuration aligned to Mistral.
Phase 1 locked contracts using Pydantic schemas and a strict graph state that already includes security fields.
Phase 2 implemented local tool APIs behind a central registry enforcing role-based permissions, validation, and retries.
Phase 3 added durable SQLite memory with customer and case tables, plus a hard block on raw email persistence.
Phase 4 introduced secure RAG on internal bilingual policy docs, with prompt-injection filtering at indexing and retrieval, language-aware retrieval, and metadata-based controls.
The result is a deterministic, testable, and security-first foundation ready for agent orchestration in upcoming phases."

